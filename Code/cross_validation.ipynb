{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Um_TiVf5Zi7F"
   },
   "source": [
    "# CS 6120: Natural Language Processing\n",
    "## Final Project: Music Genre Classification\n",
    "## Authors: Bharat Chawla and Himaja R. Ginkala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2xzKLoC9Zho9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/chawla.bh/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# importing libraries\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Activation, Attention, Dense, Dropout, Embedding, Flatten, Layer, LSTM, MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "id": "rMBUHH8uXPc0",
    "outputId": "6bf7119f-b513-4948-fe80-64cb8786b687"
   },
   "outputs": [],
   "source": [
    "# load data from CSV file\n",
    "df_english_cleaned = pd.read_csv('english_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJMYUfGwh2JI"
   },
   "source": [
    "#### Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WVywQ-2f_QVS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size:  186126\n"
     ]
    }
   ],
   "source": [
    "# load vocabulary from file\n",
    "with open('vocabulary.txt', \"r\") as f:\n",
    "    vocabulary = f.readlines()\n",
    "\n",
    "print(\"Vocabulary Size: \", len(vocabulary))\n",
    "\n",
    "# replace new line characters\n",
    "vocabulary = list(map(lambda s: s.strip(), vocabulary))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "meyLwLCYh9sK"
   },
   "outputs": [],
   "source": [
    "# create word to id dictionary\n",
    "word_to_id = {}\n",
    "for i, word in enumerate(vocabulary):\n",
    "  word_to_id[word] = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y8Ol89l3jFVA"
   },
   "source": [
    "#### Glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tD51htbrjFcR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# open glove embeddings file\n",
    "glove_file = open('glove.6B.100d.txt')\n",
    "\n",
    "glove_embeddings = {}\n",
    "for line in glove_file:\n",
    "  values = line.split()\n",
    "  word = values[0]\n",
    "  coefs = np.asarray(values[1:], dtype = 'float32')\n",
    "  glove_embeddings[word] = coefs\n",
    "\n",
    "glove_file.close()\n",
    "\n",
    "all_glove_words = list(glove_embeddings.keys())\n",
    "print(\"Found %s word vectors.\" % len(glove_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "959Ys89FsDg7"
   },
   "source": [
    "#### Embedding Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "e6e_ZxA2p2jo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(186126, 100)\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = np.zeros((len(vocabulary), 100))\n",
    "\n",
    "for word, i in word_to_id.items():\n",
    "  embedding_vector = glove_embeddings.get(word)\n",
    "  if embedding_vector is not None:\n",
    "    embedding_matrix[i] = embedding_vector\n",
    "\n",
    "print(embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kVedmopMJmFi"
   },
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "OV9R2GxSGwDK"
   },
   "outputs": [],
   "source": [
    "# get only data with cleaned lyrics\n",
    "df_english = df_english_cleaned[df_english_cleaned['Cleaned_Lyric'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WAXOZmD4KdV9"
   },
   "source": [
    "#### Genre Separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ie2Z67H2gcvs"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>SName</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Language</th>\n",
       "      <th>Cleaned_Lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>Pop</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>feel unsure take hand lead dance floor music d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>let fool ya even try school ya oh got mind go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>baby let cruise away confused way clear want g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>know sounds funny stand pain girl leaving tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>Pop</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>got look one hoped lad face beaming smile got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191382</th>\n",
       "      <td>Johnny Clegg</td>\n",
       "      <td>The Waiting</td>\n",
       "      <td>World Music</td>\n",
       "      <td>Chorus\\nHere we stand waiting on the plain\\nDa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>chorus stand waiting plain darkness taken last...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191383</th>\n",
       "      <td>Johnny Clegg</td>\n",
       "      <td>Too Early For The Sky</td>\n",
       "      <td>World Music</td>\n",
       "      <td>I nearly disappeared into the mouth of a croco...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>nearly disappeared mouth crocodile nearly touc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191384</th>\n",
       "      <td>Johnny Clegg</td>\n",
       "      <td>Warsaw 1943 (I Never Betrayed The Revolution)</td>\n",
       "      <td>World Music</td>\n",
       "      <td>Amambuka, amambuka azothengisa izwe lakithi, i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>amambuka amambuka azothengisa izwe lakithi izw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191385</th>\n",
       "      <td>Johnny Clegg</td>\n",
       "      <td>When The System Has Fallen</td>\n",
       "      <td>World Music</td>\n",
       "      <td>Sweat in the heat for days on end\\nwaiting for...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>sweat heat days end waiting come hear words sp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191386</th>\n",
       "      <td>Johnny Clegg</td>\n",
       "      <td>Woman Be My Country</td>\n",
       "      <td>World Music</td>\n",
       "      <td>Here we stand on the edge of the day\\nFaces me...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>stand edge day faces melting african rain many...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>191384 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Artist                                              SName  \\\n",
       "0       Ivete Sangalo                                   Careless Whisper   \n",
       "1       Ivete Sangalo  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "2       Ivete Sangalo                             Cruisin' (Part. Saulo)   \n",
       "3       Ivete Sangalo                                               Easy   \n",
       "4       Ivete Sangalo                  For Your Babies (The Voice cover)   \n",
       "...               ...                                                ...   \n",
       "191382   Johnny Clegg                                        The Waiting   \n",
       "191383   Johnny Clegg                              Too Early For The Sky   \n",
       "191384   Johnny Clegg      Warsaw 1943 (I Never Betrayed The Revolution)   \n",
       "191385   Johnny Clegg                         When The System Has Fallen   \n",
       "191386   Johnny Clegg                                Woman Be My Country   \n",
       "\n",
       "              Genre                                              Lyric  \\\n",
       "0               Pop  I feel so unsure\\nAs I take your hand and lead...   \n",
       "1               Pop  Don't let them fool, ya\\nOr even try to school...   \n",
       "2               Pop  Baby, let's cruise, away from here\\nDon't be c...   \n",
       "3               Pop  Know it sounds funny\\nBut, I just can't stand ...   \n",
       "4               Pop  You've got that look again\\nThe one I hoped I ...   \n",
       "...             ...                                                ...   \n",
       "191382  World Music  Chorus\\nHere we stand waiting on the plain\\nDa...   \n",
       "191383  World Music  I nearly disappeared into the mouth of a croco...   \n",
       "191384  World Music  Amambuka, amambuka azothengisa izwe lakithi, i...   \n",
       "191385  World Music  Sweat in the heat for days on end\\nwaiting for...   \n",
       "191386  World Music  Here we stand on the edge of the day\\nFaces me...   \n",
       "\n",
       "        Popularity Language                                      Cleaned_Lyric  \n",
       "0              4.4       en  feel unsure take hand lead dance floor music d...  \n",
       "1              4.4       en  let fool ya even try school ya oh got mind go ...  \n",
       "2              4.4       en  baby let cruise away confused way clear want g...  \n",
       "3              4.4       en  know sounds funny stand pain girl leaving tomo...  \n",
       "4              4.4       en  got look one hoped lad face beaming smile got ...  \n",
       "...            ...      ...                                                ...  \n",
       "191382         0.0       en  chorus stand waiting plain darkness taken last...  \n",
       "191383         0.0       en  nearly disappeared mouth crocodile nearly touc...  \n",
       "191384         0.0       en  amambuka amambuka azothengisa izwe lakithi izw...  \n",
       "191385         0.0       en  sweat heat days end waiting come hear words sp...  \n",
       "191386         0.0       en  stand edge day faces melting african rain many...  \n",
       "\n",
       "[191384 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert multi-valued column to single value\n",
    "for i, row in df_english.iterrows():\n",
    "  if \";\" in str(df_english.at[i, 'Genres']):\n",
    "    genres = df_english.at[i, 'Genres'].split(\"; \")\n",
    "    df_english.at[i, 'Genres'] = genres[0]\n",
    "\n",
    "#rename column\n",
    "df_english.rename(columns = {'Genres':'Genre'}, inplace = True)\n",
    "df_english['Genre'] = df_english['Genre'].replace('Pop/Rock', 'Pop-Rock')\n",
    "df_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "12G1Oy0bKTPg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English Genres:  Rock             25177\n",
      "Pop              13759\n",
      "Heavy Metal      13496\n",
      "Indie            12998\n",
      "Rap               9589\n",
      "                 ...  \n",
      "Electro Swing        6\n",
      "Jovem Guarda         6\n",
      "Forró                3\n",
      "Regional             1\n",
      "Lo-fi                1\n",
      "Name: Genre, Length: 73, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# get genre count\n",
    "genre_counts = df_english['Genre'].value_counts()\n",
    "print(\"Number of English Genres: \", genre_counts)\n",
    "\n",
    "# get genre names\n",
    "genre_names = df_english['Genre'].value_counts().index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KnXdBBzQJqOZ"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>SName</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Language</th>\n",
       "      <th>Cleaned_Lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>Pop</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>feel unsure take hand lead dance floor music d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>let fool ya even try school ya oh got mind go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>baby let cruise away confused way clear want g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>know sounds funny stand pain girl leaving tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>Pop</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>got look one hoped lad face beaming smile got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182627</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>Words And Guitar</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>words + guitar\\ni got it words + guitar\\ni lik...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>words guitar got words guitar like way way lou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182628</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>Write Me Back, Fucker</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>i got your letter today\\ni read the things you...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>got letter today read things say things took b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182629</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>You Ain't It</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>you ...ain't it!\\nyou ...ain't it!\\n\\nyou're t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>hottest band around biggest dicks town mean sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182630</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>You're No Rock N' Roll Fun</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>You're no rock n' roll fun\\nlike a party that'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>rock n roll fun like party begun walk park lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182631</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>Youth Decay</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>Acid tooth\\nIt's got nothing to do with you\\nb...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>acid tooth got nothing wan na watch chew teeth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110690 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Artist                                              SName  \\\n",
       "0        Ivete Sangalo                                   Careless Whisper   \n",
       "1        Ivete Sangalo  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "2        Ivete Sangalo                             Cruisin' (Part. Saulo)   \n",
       "3        Ivete Sangalo                                               Easy   \n",
       "4        Ivete Sangalo                  For Your Babies (The Voice cover)   \n",
       "...                ...                                                ...   \n",
       "182627  Sleater-Kinney                                   Words And Guitar   \n",
       "182628  Sleater-Kinney                              Write Me Back, Fucker   \n",
       "182629  Sleater-Kinney                                       You Ain't It   \n",
       "182630  Sleater-Kinney                         You're No Rock N' Roll Fun   \n",
       "182631  Sleater-Kinney                                        Youth Decay   \n",
       "\n",
       "                   Genre                                              Lyric  \\\n",
       "0                    Pop  I feel so unsure\\nAs I take your hand and lead...   \n",
       "1                    Pop  Don't let them fool, ya\\nOr even try to school...   \n",
       "2                    Pop  Baby, let's cruise, away from here\\nDon't be c...   \n",
       "3                    Pop  Know it sounds funny\\nBut, I just can't stand ...   \n",
       "4                    Pop  You've got that look again\\nThe one I hoped I ...   \n",
       "...                  ...                                                ...   \n",
       "182627  Rock Alternativo  words + guitar\\ni got it words + guitar\\ni lik...   \n",
       "182628  Rock Alternativo  i got your letter today\\ni read the things you...   \n",
       "182629  Rock Alternativo  you ...ain't it!\\nyou ...ain't it!\\n\\nyou're t...   \n",
       "182630  Rock Alternativo  You're no rock n' roll fun\\nlike a party that'...   \n",
       "182631  Rock Alternativo  Acid tooth\\nIt's got nothing to do with you\\nb...   \n",
       "\n",
       "        Popularity Language                                      Cleaned_Lyric  \n",
       "0              4.4       en  feel unsure take hand lead dance floor music d...  \n",
       "1              4.4       en  let fool ya even try school ya oh got mind go ...  \n",
       "2              4.4       en  baby let cruise away confused way clear want g...  \n",
       "3              4.4       en  know sounds funny stand pain girl leaving tomo...  \n",
       "4              4.4       en  got look one hoped lad face beaming smile got ...  \n",
       "...            ...      ...                                                ...  \n",
       "182627         0.0       en  words guitar got words guitar like way way lou...  \n",
       "182628         0.0       en  got letter today read things say things took b...  \n",
       "182629         0.0       en  hottest band around biggest dicks town mean sh...  \n",
       "182630         0.0       en  rock n roll fun like party begun walk park lik...  \n",
       "182631         0.0       en  acid tooth got nothing wan na watch chew teeth...  \n",
       "\n",
       "[110690 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dataframe of only top 10 genres in English\n",
    "top_10_genres = genre_names[0:10]\n",
    "df_english_top_10_genres = df_english[df_english['Genre'].isin(top_10_genres)]\n",
    "df_english_top_10_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "EXCvOYTG-fsO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Artist</th>\n",
       "      <th>SName</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Popularity</th>\n",
       "      <th>Language</th>\n",
       "      <th>Cleaned_Lyric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Careless Whisper</td>\n",
       "      <td>Pop</td>\n",
       "      <td>I feel so unsure\\nAs I take your hand and lead...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>feel unsure take hand lead dance floor music d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Could You Be Loved / Citação Musical do Rap: S...</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Don't let them fool, ya\\nOr even try to school...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>let fool ya even try school ya oh got mind go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Cruisin' (Part. Saulo)</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Baby, let's cruise, away from here\\nDon't be c...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>baby let cruise away confused way clear want g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>Easy</td>\n",
       "      <td>Pop</td>\n",
       "      <td>Know it sounds funny\\nBut, I just can't stand ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>know sounds funny stand pain girl leaving tomo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ivete Sangalo</td>\n",
       "      <td>For Your Babies (The Voice cover)</td>\n",
       "      <td>Pop</td>\n",
       "      <td>You've got that look again\\nThe one I hoped I ...</td>\n",
       "      <td>4.4</td>\n",
       "      <td>en</td>\n",
       "      <td>got look one hoped lad face beaming smile got ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110685</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>Words And Guitar</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>words + guitar\\ni got it words + guitar\\ni lik...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>words guitar got words guitar like way way lou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110686</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>Write Me Back, Fucker</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>i got your letter today\\ni read the things you...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>got letter today read things say things took b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110687</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>You Ain't It</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>you ...ain't it!\\nyou ...ain't it!\\n\\nyou're t...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>hottest band around biggest dicks town mean sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110688</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>You're No Rock N' Roll Fun</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>You're no rock n' roll fun\\nlike a party that'...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>rock n roll fun like party begun walk park lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110689</th>\n",
       "      <td>Sleater-Kinney</td>\n",
       "      <td>Youth Decay</td>\n",
       "      <td>Rock Alternativo</td>\n",
       "      <td>Acid tooth\\nIt's got nothing to do with you\\nb...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>en</td>\n",
       "      <td>acid tooth got nothing wan na watch chew teeth...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110690 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Artist                                              SName  \\\n",
       "0        Ivete Sangalo                                   Careless Whisper   \n",
       "1        Ivete Sangalo  Could You Be Loved / Citação Musical do Rap: S...   \n",
       "2        Ivete Sangalo                             Cruisin' (Part. Saulo)   \n",
       "3        Ivete Sangalo                                               Easy   \n",
       "4        Ivete Sangalo                  For Your Babies (The Voice cover)   \n",
       "...                ...                                                ...   \n",
       "110685  Sleater-Kinney                                   Words And Guitar   \n",
       "110686  Sleater-Kinney                              Write Me Back, Fucker   \n",
       "110687  Sleater-Kinney                                       You Ain't It   \n",
       "110688  Sleater-Kinney                         You're No Rock N' Roll Fun   \n",
       "110689  Sleater-Kinney                                        Youth Decay   \n",
       "\n",
       "                   Genre                                              Lyric  \\\n",
       "0                    Pop  I feel so unsure\\nAs I take your hand and lead...   \n",
       "1                    Pop  Don't let them fool, ya\\nOr even try to school...   \n",
       "2                    Pop  Baby, let's cruise, away from here\\nDon't be c...   \n",
       "3                    Pop  Know it sounds funny\\nBut, I just can't stand ...   \n",
       "4                    Pop  You've got that look again\\nThe one I hoped I ...   \n",
       "...                  ...                                                ...   \n",
       "110685  Rock Alternativo  words + guitar\\ni got it words + guitar\\ni lik...   \n",
       "110686  Rock Alternativo  i got your letter today\\ni read the things you...   \n",
       "110687  Rock Alternativo  you ...ain't it!\\nyou ...ain't it!\\n\\nyou're t...   \n",
       "110688  Rock Alternativo  You're no rock n' roll fun\\nlike a party that'...   \n",
       "110689  Rock Alternativo  Acid tooth\\nIt's got nothing to do with you\\nb...   \n",
       "\n",
       "        Popularity Language                                      Cleaned_Lyric  \n",
       "0              4.4       en  feel unsure take hand lead dance floor music d...  \n",
       "1              4.4       en  let fool ya even try school ya oh got mind go ...  \n",
       "2              4.4       en  baby let cruise away confused way clear want g...  \n",
       "3              4.4       en  know sounds funny stand pain girl leaving tomo...  \n",
       "4              4.4       en  got look one hoped lad face beaming smile got ...  \n",
       "...            ...      ...                                                ...  \n",
       "110685         0.0       en  words guitar got words guitar like way way lou...  \n",
       "110686         0.0       en  got letter today read things say things took b...  \n",
       "110687         0.0       en  hottest band around biggest dicks town mean sh...  \n",
       "110688         0.0       en  rock n roll fun like party begun walk park lik...  \n",
       "110689         0.0       en  acid tooth got nothing wan na watch chew teeth...  \n",
       "\n",
       "[110690 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset indices\n",
    "df_english_top_10_genres = df_english_top_10_genres.reset_index(drop = True)\n",
    "df_english_top_10_genres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyrTIGWqKfcg"
   },
   "source": [
    "#### Label Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "nbpB7BD7Jzzh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Labels List:  110690\n"
     ]
    }
   ],
   "source": [
    "# create labels\n",
    "genre_labels = []\n",
    "for genre in df_english_top_10_genres['Genre'].tolist():\n",
    "  genre_labels.append(top_10_genres.index(genre))\n",
    "\n",
    "print(\"Length of Labels List: \", len(genre_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "6wip677fQthv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    25177\n",
      "1    13759\n",
      "2    13496\n",
      "3    12998\n",
      "4     9589\n",
      "5     9019\n",
      "6     8411\n",
      "7     7377\n",
      "8     5555\n",
      "9     5309\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df_english_top_10_genres['Label'] = genre_labels\n",
    "print(df_english_top_10_genres['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew2R3kKog3Si"
   },
   "source": [
    "#### Balancing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "fPiXh9xYg3c9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop-Rock            2000\n",
       "Rap                 2000\n",
       "Pop                 2000\n",
       "Rock                2000\n",
       "Hip Hop             2000\n",
       "Country             2000\n",
       "Heavy Metal         2000\n",
       "Rock Alternativo    2000\n",
       "R&B                 2000\n",
       "Indie               2000\n",
       "Name: Genre, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a balanced dataset starting with top genre\n",
    "df_balanced = df_english_top_10_genres[df_english_top_10_genres.Genre == top_10_genres[0]].sample(2000)\n",
    "\n",
    "# get n random rows from each of the other top genres\n",
    "for genre in top_10_genres[1:]:\n",
    "  df_genre = df_english_top_10_genres[df_english_top_10_genres.Genre == genre].sample(2000)\n",
    "  df_balanced = pd.concat([df_balanced, df_genre], ignore_index = True)\n",
    "\n",
    "# ensure dataset is balanced\n",
    "df_balanced['Genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OvgGQEQxRqQz"
   },
   "source": [
    "#### Tokenization and Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5YK0zftTl4yx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Tokens List:  20000\n"
     ]
    }
   ],
   "source": [
    "lyrics = df_balanced['Cleaned_Lyric'].tolist()\n",
    "\n",
    "tokens = []\n",
    "for lyric in lyrics:\n",
    "  try:\n",
    "    words = word_tokenize(lyric)\n",
    "  except:\n",
    "    print(lyric)\n",
    "\n",
    "  tokens.append(words)\n",
    "\n",
    "print(\"Length of Tokens List: \", len(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "cs3p4z_Lk7uB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Encoded Tokens:  20000\n"
     ]
    }
   ],
   "source": [
    "encoded_tokens = []\n",
    "\n",
    "# for every lyric\n",
    "for line in tokens:\n",
    "  encoded_line = []\n",
    "\n",
    "  # for every word in lyric\n",
    "  for word in line:\n",
    "    # set to id value\n",
    "    encoded_line.append(word_to_id.get(word))\n",
    "\n",
    "  encoded_tokens.append(encoded_line)\n",
    "\n",
    "print(\"Length of Encoded Tokens: \", len(encoded_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3yoGuG_xoZm"
   },
   "source": [
    "#### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "D1tQI-3Dxokn"
   },
   "outputs": [],
   "source": [
    "# get max length in list\n",
    "max_length = len(max(encoded_tokens, key = len))\n",
    "# pad training data\n",
    "X = pad_sequences(encoded_tokens, maxlen = max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "X6xLOGu_ckrw"
   },
   "outputs": [],
   "source": [
    "# convert to numpy arrays\n",
    "X = np.array(X)\n",
    "y = np.array(df_balanced['Label'].tolist())\n",
    "\n",
    "# one hot encode labels\n",
    "y = OneHotEncoder().fit_transform(y.reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vnWZZ7zNG80U"
   },
   "source": [
    "### Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0Ahl0B9Zglbj"
   },
   "outputs": [],
   "source": [
    "# global variables\n",
    "EPOCHS = 5\n",
    "DROPOUT = 0.2\n",
    "LEARNING_RATE = 0.003\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "VOCAB_SIZE = len(vocabulary)\n",
    "OUTPUT_SIZE = 10\n",
    "N_LAYERS = 2\n",
    "HIDDEN_DIM = 128\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Ip-MEL9aG_nv"
   },
   "outputs": [],
   "source": [
    "def build_model(X):\n",
    "\n",
    "  # set input layer\n",
    "  input_layer = tf.keras.Input((X.shape[1],))\n",
    "\n",
    "  # add embedding layer\n",
    "  m = tf.keras.layers.Embedding(VOCAB_SIZE, EMBEDDING_DIM, weights=[embedding_matrix])(input_layer)\n",
    "\n",
    "  # add LSTM layer\n",
    "  m = tf.keras.layers.LSTM(HIDDEN_DIM, return_sequences=True)(m)\n",
    "\n",
    "  # add attention layer\n",
    "  m = tf.keras.layers.Attention()([m, m])\n",
    "\n",
    "  # add global average pooling layer\n",
    "  m = tf.keras.layers.GlobalAveragePooling1D()(m)\n",
    "\n",
    "  # add dropout layer\n",
    "  m = tf.keras.layers.Dropout(DROPOUT)(m)\n",
    "\n",
    "  # add linear layer\n",
    "  m = tf.keras.layers.Dense(OUTPUT_SIZE, activation='softmax')(m)\n",
    "\n",
    "  # build model\n",
    "  model = tf.keras.models.Model(inputs = input_layer, outputs = m)\n",
    "\n",
    "  # compile model\n",
    "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['AUC', 'Precision', 'Accuracy', 'Recall'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "GXUvgUeqgLc8"
   },
   "outputs": [],
   "source": [
    "# keras.utils.plot_model(model, show_shapes = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "je6LAySfaFG2"
   },
   "source": [
    "### Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "-N3NkIDOMDsa",
    "outputId": "d99bb309-4060-453d-c462-9a2597dc9f75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 2000  2001  2002 ... 19997 19998 19999] TEST: [   0    1    2 ... 1997 1998 1999]\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 1657)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, 1657, 100)            1861260   ['input_1[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 (None, 1657, 128)            117248    ['embedding[0][0]']           \n",
      "                                                                                                  \n",
      " attention (Attention)       (None, 1657, 128)            0         ['lstm[0][0]',                \n",
      "                                                                     'lstm[0][0]']                \n",
      "                                                                                                  \n",
      " global_average_pooling1d (  (None, 128)                  0         ['attention[0][0]']           \n",
      " GlobalAveragePooling1D)                                                                          \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, 128)                  0         ['global_average_pooling1d[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 10)                   1290      ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18731138 (71.45 MB)\n",
      "Trainable params: 18731138 (71.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 477s 3s/step - loss: 1.7364 - auc: 0.8156 - precision: 0.5930 - Accuracy: 0.3088 - recall: 0.0726 - val_loss: 6.5006 - val_auc: 0.2359 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 476s 3s/step - loss: 1.4371 - auc: 0.8812 - precision: 0.6164 - Accuracy: 0.4192 - recall: 0.1860 - val_loss: 6.7297 - val_auc: 0.2741 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 480s 3s/step - loss: 1.3070 - auc: 0.9029 - precision: 0.6479 - Accuracy: 0.4739 - recall: 0.2529 - val_loss: 6.9286 - val_auc: 0.2924 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 486s 3s/step - loss: 1.1949 - auc: 0.9193 - precision: 0.6772 - Accuracy: 0.5131 - recall: 0.3115 - val_loss: 7.4391 - val_auc: 0.3047 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 499s 3s/step - loss: 1.0774 - auc: 0.9344 - precision: 0.7028 - Accuracy: 0.5639 - recall: 0.3858 - val_loss: 7.5578 - val_auc: 0.3428 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "TRAIN: [    0     1     2 ... 19997 19998 19999] TEST: [2000 2001 2002 ... 3997 3998 3999]\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 1657)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, 1657, 100)            1861260   ['input_2[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               (None, 1657, 128)            117248    ['embedding_1[0][0]']         \n",
      "                                                                                                  \n",
      " attention_1 (Attention)     (None, 1657, 128)            0         ['lstm_1[0][0]',              \n",
      "                                                                     'lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_1  (None, 128)                  0         ['attention_1[0][0]']         \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128)                  0         ['global_average_pooling1d_1[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 10)                   1290      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18731138 (71.45 MB)\n",
      "Trainable params: 18731138 (71.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 497s 3s/step - loss: 1.7211 - auc: 0.8181 - precision: 0.5865 - Accuracy: 0.3067 - recall: 0.0760 - val_loss: 6.8837 - val_auc: 0.2441 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 496s 3s/step - loss: 1.4670 - auc: 0.8753 - precision: 0.6028 - Accuracy: 0.4031 - recall: 0.1800 - val_loss: 6.3804 - val_auc: 0.2643 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 495s 3s/step - loss: 1.3268 - auc: 0.8999 - precision: 0.6254 - Accuracy: 0.4594 - recall: 0.2483 - val_loss: 7.1472 - val_auc: 0.2920 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 495s 3s/step - loss: 1.2184 - auc: 0.9163 - precision: 0.6447 - Accuracy: 0.4978 - recall: 0.3047 - val_loss: 7.5471 - val_auc: 0.3147 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 497s 3s/step - loss: 1.0977 - auc: 0.9320 - precision: 0.6698 - Accuracy: 0.5495 - recall: 0.3738 - val_loss: 7.7678 - val_auc: 0.3545 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "TRAIN: [    0     1     2 ... 19997 19998 19999] TEST: [4000 4001 4002 ... 5997 5998 5999]\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_3 (InputLayer)        [(None, 1657)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)     (None, 1657, 100)            1861260   ['input_3[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               (None, 1657, 128)            117248    ['embedding_2[0][0]']         \n",
      "                                                                                                  \n",
      " attention_2 (Attention)     (None, 1657, 128)            0         ['lstm_2[0][0]',              \n",
      "                                                                     'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_2  (None, 128)                  0         ['attention_2[0][0]']         \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, 128)                  0         ['global_average_pooling1d_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 10)                   1290      ['dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18731138 (71.45 MB)\n",
      "Trainable params: 18731138 (71.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 498s 3s/step - loss: 1.8133 - auc: 0.7905 - precision: 0.4904 - Accuracy: 0.2460 - recall: 0.0390 - val_loss: 6.1814 - val_auc: 0.2031 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 500s 3s/step - loss: 1.6033 - auc: 0.8451 - precision: 0.5182 - Accuracy: 0.3256 - recall: 0.0882 - val_loss: 6.5441 - val_auc: 0.2225 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 497s 3s/step - loss: 1.5028 - auc: 0.8681 - precision: 0.5436 - Accuracy: 0.3782 - recall: 0.1347 - val_loss: 7.3556 - val_auc: 0.2610 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 498s 3s/step - loss: 1.4204 - auc: 0.8838 - precision: 0.5681 - Accuracy: 0.4134 - recall: 0.1685 - val_loss: 7.4524 - val_auc: 0.2819 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 498s 3s/step - loss: 1.3027 - auc: 0.9034 - precision: 0.6159 - Accuracy: 0.4663 - recall: 0.2369 - val_loss: 8.7045 - val_auc: 0.3012 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "TRAIN: [    0     1     2 ... 19997 19998 19999] TEST: [6000 6001 6002 ... 7997 7998 7999]\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_4 (InputLayer)        [(None, 1657)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)     (None, 1657, 100)            1861260   ['input_4[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               (None, 1657, 128)            117248    ['embedding_3[0][0]']         \n",
      "                                                                                                  \n",
      " attention_3 (Attention)     (None, 1657, 128)            0         ['lstm_3[0][0]',              \n",
      "                                                                     'lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_3  (None, 128)                  0         ['attention_3[0][0]']         \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, 128)                  0         ['global_average_pooling1d_3[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 10)                   1290      ['dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18731138 (71.45 MB)\n",
      "Trainable params: 18731138 (71.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 501s 3s/step - loss: 1.7842 - auc: 0.8016 - precision: 0.4920 - Accuracy: 0.2738 - recall: 0.0404 - val_loss: 5.9154 - val_auc: 0.1755 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 503s 3s/step - loss: 1.5055 - auc: 0.8687 - precision: 0.5905 - Accuracy: 0.3872 - recall: 0.1438 - val_loss: 6.7749 - val_auc: 0.2525 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 502s 3s/step - loss: 1.3828 - auc: 0.8907 - precision: 0.6149 - Accuracy: 0.4317 - recall: 0.1938 - val_loss: 7.3253 - val_auc: 0.2671 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 501s 3s/step - loss: 1.2776 - auc: 0.9075 - precision: 0.6384 - Accuracy: 0.4822 - recall: 0.2597 - val_loss: 7.9329 - val_auc: 0.3140 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 501s 3s/step - loss: 1.1739 - auc: 0.9224 - precision: 0.6736 - Accuracy: 0.5267 - recall: 0.3265 - val_loss: 8.0699 - val_auc: 0.3379 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "TRAIN: [    0     1     2 ... 19997 19998 19999] TEST: [8000 8001 8002 ... 9997 9998 9999]\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_5 (InputLayer)        [(None, 1657)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)     (None, 1657, 100)            1861260   ['input_5[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               (None, 1657, 128)            117248    ['embedding_4[0][0]']         \n",
      "                                                                                                  \n",
      " attention_4 (Attention)     (None, 1657, 128)            0         ['lstm_4[0][0]',              \n",
      "                                                                     'lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_4  (None, 128)                  0         ['attention_4[0][0]']         \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 128)                  0         ['global_average_pooling1d_4[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 10)                   1290      ['dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18731138 (71.45 MB)\n",
      "Trainable params: 18731138 (71.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 512s 4s/step - loss: 1.7870 - auc: 0.7912 - precision: 0.7678 - Accuracy: 0.3145 - recall: 0.0921 - val_loss: 5.5732 - val_auc: 0.1898 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 509s 4s/step - loss: 1.5361 - auc: 0.8560 - precision: 0.7803 - Accuracy: 0.4227 - recall: 0.1981 - val_loss: 6.3994 - val_auc: 0.2315 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 507s 4s/step - loss: 1.4162 - auc: 0.8808 - precision: 0.7822 - Accuracy: 0.4774 - recall: 0.2509 - val_loss: 6.8916 - val_auc: 0.2550 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 508s 4s/step - loss: 1.2958 - auc: 0.9023 - precision: 0.7950 - Accuracy: 0.5207 - recall: 0.3019 - val_loss: 7.8838 - val_auc: 0.2976 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 508s 4s/step - loss: 1.1717 - auc: 0.9212 - precision: 0.8024 - Accuracy: 0.5655 - recall: 0.3675 - val_loss: 8.1152 - val_auc: 0.3008 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "TRAIN: [    0     1     2 ... 19997 19998 19999] TEST: [10000 10001 10002 ... 11997 11998 11999]\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_6 (InputLayer)        [(None, 1657)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)     (None, 1657, 100)            1861260   ['input_6[0][0]']             \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " lstm_5 (LSTM)               (None, 1657, 128)            117248    ['embedding_5[0][0]']         \n",
      "                                                                                                  \n",
      " attention_5 (Attention)     (None, 1657, 128)            0         ['lstm_5[0][0]',              \n",
      "                                                                     'lstm_5[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling1d_5  (None, 128)                  0         ['attention_5[0][0]']         \n",
      "  (GlobalAveragePooling1D)                                                                        \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 128)                  0         ['global_average_pooling1d_5[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 10)                   1290      ['dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 18731138 (71.45 MB)\n",
      "Trainable params: 18731138 (71.45 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "144/144 [==============================] - 512s 4s/step - loss: 1.7152 - auc: 0.8205 - precision: 0.5821 - Accuracy: 0.3141 - recall: 0.0731 - val_loss: 6.6772 - val_auc: 0.2121 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 510s 4s/step - loss: 1.4565 - auc: 0.8777 - precision: 0.5999 - Accuracy: 0.4117 - recall: 0.1831 - val_loss: 6.4711 - val_auc: 0.2596 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 512s 4s/step - loss: 1.3230 - auc: 0.9005 - precision: 0.6237 - Accuracy: 0.4660 - recall: 0.2535 - val_loss: 7.0086 - val_auc: 0.2845 - val_precision: 0.0000e+00 - val_Accuracy: 0.0000e+00 - val_recall: 0.0000e+00\n",
      "Epoch 4/5\n",
      " 66/144 [============>.................] - ETA: 4:15 - loss: 1.2579 - auc: 0.9107 - precision: 0.6482 - Accuracy: 0.4964 - recall: 0.2873"
     ]
    }
   ],
   "source": [
    "# track k fold history\n",
    "history = []\n",
    "\n",
    "kf = KFold(n_splits = 10)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "\n",
    "  print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "\n",
    "  X_train, X_test, y_train, y_test = X[train_index], X[test_index], y[train_index], y[test_index]\n",
    "\n",
    "  model = build_model(X_train)\n",
    "\n",
    "  model.summary()\n",
    "\n",
    "  h = model.fit(X_train, y_train, batch_size = BATCH_SIZE, epochs = EPOCHS, validation_split = 0.2)\n",
    "\n",
    "  history.append(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Uzh-8xDaI1o"
   },
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8XR5JZpFH3d"
   },
   "outputs": [],
   "source": [
    "for (i, h) in enumerate(history, start = 1):\n",
    "  print(\"Begin KFold: \", i)\n",
    "\n",
    "  print(h.history['loss'])\n",
    "  print(h.history['val_loss'])\n",
    "\n",
    "  print(h.history['auc'])\n",
    "  print(h.history['val_auc'])\n",
    "\n",
    "  print(h.history['recall'])\n",
    "  print(h.history['val_recall'])\n",
    "\n",
    "  print(h.history['precision'])\n",
    "  print(h.history['val_precision'])\n",
    "\n",
    "  print(h.history['Accuracy'])\n",
    "  print(h.history['val_Accuracy'])\n",
    "\n",
    "  print(\"End KFold: \", i)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
